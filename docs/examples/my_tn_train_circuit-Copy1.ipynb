{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "import quimb as qu\n",
    "import quimb.tensor as qtn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "gate2 = 'CZ'\n",
    "\n",
    "# the hamiltonian\n",
    "H = qu.ham_ising(n, jz=1.0, bx=0.7, cyclic=False)\n",
    "\n",
    "# the propagator for the hamiltonian\n",
    "t = 2\n",
    "U_dense = qu.expm(-1j * t * H)\n",
    "\n",
    "# 'tensorized' version of the unitary propagator\n",
    "U = qtn.Tensor(\n",
    "    data=U_dense.reshape([2] * (2 * n)),\n",
    "    inds=[f'k{i}' for i in range(n)] + [f'b{i}' for i in range(n)],\n",
    "    tags={'U_TARGET'}\n",
    ")\n",
    "U.draw(color=[ 'U_TARGET','MPO'])\n",
    "\n",
    "chi = [2,2,3,3,2,2]\n",
    "\n",
    "d = 2\n",
    "tn_guess = qtn.TensorNetwork([\n",
    "    qtn.Tensor(np.random.normal(size=(d, d, chi[0], chi[1])), inds=(f'b{0}',f'k{0}',f'l{0}',f'l{1}' ),tags={'MPO'}),\n",
    "    qtn.Tensor(np.random.normal(size=(d, d, chi[1], chi[2])), inds=(f'b{1}',f'k{1}',f'l{1}',f'l{2}' ),tags={'MPO'}),\n",
    "    qtn.Tensor(np.random.normal(size=(d, d, chi[2], chi[3])), inds=(f'b{2}',f'k{2}',f'l{2}',f'l{3}' ),tags={'MPO'}),\n",
    "    qtn.Tensor(np.random.normal(size=(d, d, chi[3], chi[4])), inds=(f'b{3}',f'k{3}',f'l{3}',f'l{4}' ),tags={'MPO'}),\n",
    "    qtn.Tensor(np.random.normal(size=(d, d, chi[4], chi[5])), inds=(f'b{4}',f'k{4}',f'l{4}',f'l{5}' ),tags={'MPO'}),\n",
    "    qtn.Tensor(np.random.normal(size=(d, d, chi[5], chi[0])), inds=(f'b{5}',f'k{5}',f'l{5}',f'l{0}' ),tags={'MPO'})\n",
    "])\n",
    "tn_guess.draw(color=[ 'U_TARGET','MPO'])\n",
    "\n",
    "(tn_guess.H & U).draw(color=['U_TARGET','MPO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_op(mpo):\n",
    "    mpo /= mpo.norm()\n",
    "    mpo *= np.sqrt(2**n)\n",
    "    return mpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_overlap(mpo, U):\n",
    "    return - abs((mpo.H & U).contract(all, optimize='auto-hq')) / 2**n #(mpo.H @ u_target)  # minus so as to minimize  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(V, U):\n",
    "    return 1 - abs((V.H & U).contract(all, optimize='auto-hq')) / 2**n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quimb.tensor.optimize import TNOptimizer\n",
    "\n",
    "optmzr = TNOptimizer(\n",
    "    tn_guess,                           # our initial input, the tensors of which to optimize\n",
    "    loss_fn=negative_overlap,\n",
    "    norm_fn=normalize_op,\n",
    "    loss_constants={'U': U},            # this is a constant TN to supply to loss_fn\n",
    "    autodiff_backend='tensorflow',      # {'jax', 'tensorflow', 'autograd'}\n",
    "    optimizer='L-BFGS-B',               # supplied to scipy.minimize\n",
    ")\n",
    "mpo_opt = optmzr.optimize(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnopt = qtn.TNOptimizer(\n",
    "    tn_guess,               # the tensor network we want to optimize\n",
    "    loss,                     # the function we want to minimize\n",
    "    loss_constants={'U': U},  # supply U to the loss function as a constant TN\n",
    "    tags=['MPO'],             # only optimize U3 tensors\n",
    "    autodiff_backend='jax',   # use 'autograd' for non-compiled optimization\n",
    "    optimizer='L-BFGS-B',     # the optimization algorithm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow 10 hops with 500 steps in each 'basin'\n",
    "tn_opt = tnopt.optimize_basinhopping(n=500, nhop=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_opt_dense = tn_opt.to_dense([f'k{i}' for i in range(n)], [f'b{i}' for i in range(n)])\n",
    "\n",
    "psi0 = qu.rand_ket(2**n)\n",
    "\n",
    "# this is the exact state we want\n",
    "psif_exact = U_dense @ psi0\n",
    "\n",
    "# this is the state our circuit will produce if fed `psi0`\n",
    "psif_apprx = tn_opt_dense @ psi0\n",
    "\n",
    "f\"Fidelity: {100 * qu.fidelity(psif_apprx, psif_exact):.2f} %\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
